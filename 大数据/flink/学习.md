

# Develop

## DataStream API

### Event Time & Watermark

#### Event Time

- **`Event time`:** Event time is the time that each individual event occurred on its producing device. 
- **`Processing time`:** Processing time refers to the system time of the machine that is executing the respective operation.

<img src="https://i.loli.net/2021/11/29/ydQ7APRi6WFbopX.png" alt="image-20211129171747959" style="zoom:50%;" />

#### Dealing With Idle Sources

#### Writing WatermarkGenerator

##### Periodic WatermarkGenerator

##### Punctuated WatermarkGenerator

#### Buildin WatermarkGenerator

### State & Fault Tolerance

#### Keyed State

`ValueState<T>`、`ListState<T>`、`ReducingState<T>`、`AggregatingState<IN, OUT>`、`MapState<UK, UV>`

键控流访问，每个键保存一个实例。

#### Operator State 

每个并行算子保存一个实例，例子：Kafka consumer

##### use operator state??

#### Brodcast State 

特殊的Operator State，用于往下游发送配置文件，用于不用并行之间共享数据。

#### Checkpointing

```java
StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();

// start a checkpoint every 1000 ms
env.enableCheckpointing(1000);

// advanced options:

// set mode to exactly-once (this is the default)
env.getCheckpointConfig().setCheckpointingMode(CheckpointingMode.EXACTLY_ONCE);

// make sure 500 ms of progress happen between checkpoints
env.getCheckpointConfig().setMinPauseBetweenCheckpoints(500);

// checkpoints have to complete within one minute, or are discarded
env.getCheckpointConfig().setCheckpointTimeout(60000);

// only two consecutive checkpoint failures are tolerated
env.getCheckpointConfig().setTolerableCheckpointFailureNumber(2);

// allow only one checkpoint to be in progress at the same time
env.getCheckpointConfig().setMaxConcurrentCheckpoints(1);

// enable externalized checkpoints which are retained
// after job cancellation
//外部持久化规则
env.getCheckpointConfig().enableExternalizedCheckpoints(
    ExternalizedCheckpointCleanup.RETAIN_ON_CANCELLATION);

// enables the unaligned checkpoints
env.getCheckpointConfig().enableUnalignedCheckpoints();

// sets the checkpoint storage where checkpoint snapshots will be written
env.getCheckpointConfig().setCheckpointStorage("hdfs:///my/checkpoint/dir")

// enable checkpointing with finished tasks
Configuration config = new Configuration();
config.set(ExecutionCheckpointingOptions.ENABLE_CHECKPOINTS_AFTER_TASKS_FINISH, true);
env.configure(config);
```

如何利用`UnionListState`保存Kafka offset，防止任务finish后offset消失??

#### State ttl??

状态存活时间策略，list/map支持到元素级别

### Operator

#### Window

#### Join

#### Aio



### Failure Recovery

In `STREAMING` execution mode, Flink uses checkpoints for failure recovery. 

One of the characteristics of checkpointing for failure recovery is that Flink will restart all the running tasks from a checkpoint in case of a failure. This can be more costly than what we have to do in `BATCH` mode (as explained below).

In `BATCH` execution mode, Flink will try and backtrack to previous processing stages for which intermediate results are still available. Potentially, only the tasks that failed (or their predecessors in the graph) will have to be restarted, which can improve processing efficiency and overall processing time of the job compared to restarting all tasks from a checkpoint.

## Table API & SQL 

# 参考

>- [官方 API](https://nightlies.apache.org/flink/flink-docs-release-1.14)
>- 
>
>

