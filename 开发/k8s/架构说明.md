**参考：**http://docs.kubernetes.org.cn/249.html

## 架构图

### 整体架构图

![img](https://i.loli.net/2021/06/05/XmKwpqEuA94WGfs.png)

### master

### ![img](https://i.loli.net/2021/06/05/tnuYSJf3shW1z6T.png)node节点

![img](https://i.loli.net/2021/06/05/RzIOcT6DxyHwQP4.png)

## 核心组件

### etcd

Etcd 是 CoreOS 基于 Raft 开发的分布式 key-value 存储,可用于服务发现、共享配置以及一致性保障(如数据库选主、分布式锁等)。
Etcd 主要功能

- 基本的 key-value 存储
- 监听机制
- key 的过期及续约机制,用于监控和服务发现
- 原子 CAS 和 CAD,用于分布式锁和 leader 选举

### Kube-apiserver

- 提供集群管理的 REST API 接口,包括认证授权、数据校验以及集群状态变更等
- 提供其他模块之间的数据交互和通信的枢纽(其他模块通过 API Server 查询或修改数据,只有 API Server 才直接操作 etcd)

### Kube-scheduler

kube-scheduler 负责分配调度 Pod 到集群内的节点上,它监听 kube-apiserver,查询还未分配 Node 的 Pod,然后根据调度策略为这些 Pod 分配节点(更新 Pod 的  NodeName  字段)

### Kube-controller-manager

Controller Manager 由 kube-controller-manager 和 cloud-controller-manager 组成,是Kubernetes 的大脑,它通过 apiserver 监控整个集群的状态,并确保集群处于预期的工作状态。

### kubelet

每个Node节点上都运行一个 Kubelet 服务进程,默认监听 10250 端口,接收并执行Master 发来的指令,管理 Pod 及 Pod 中的容器。每个 Kubelet 进程会在 API Server 上注册所在Node节点的信息,定期向 Master 节点汇报该节点的资源使用情况,并通过cAdvisor 监控节点和容器的资源

### Kube-proxy

每台机器上都运行一个 kube-proxy 服务,它监听 API server 中 service 和 endpoint 的变化情况,并通过 iptables 等来为服务配置负载均衡(仅支持 TCP 和 UDP)。
kube-proxy 可以直接运行在物理机上,也可以以 static pod 或者 daemonset 的方式运行。
kube-proxy 当前支持以下几种实现

- userspace:最早的负载均衡方案,它在用户空间监听一个端口,所有服务通过
- iptables 转发到这个端口,然后在其内部负载均衡到实际的 Pod。该方式最主要的问题是效率低,有明显的性能瓶颈。
  iptables:目前推荐的方案,完全以 iptables 规则的方式来实现 service 负载均衡。
  该方式最主要的问题是在服务多的时候产生太多的 iptables 规则,非增量式更新会引入一定的时延,大规模情况下有明显的性能问题
- ipvs:为解决 iptables 模式的性能问题,v1.11 新增了 ipvs 模式(v1.8 开始支持测试版,并在 v1.11 GA),采用增量式更新,并可以保证 service 更新期间连接保持不断开
- winuserspace:同 userspace,但仅工作在 windows 节点上

### Kube-dns

通过 kube-dns 或 CoreDNS 为集群提供dns服务

### federation

Federation目的是希望实现单一集群统一管理多个Kubernetes集群的机制，这些集群可能是跨地区(Region)，也可能是在不同公有云供应商(Cloud Provider)上，亦或者是公司内部自行建立的集群。一但集群进行联邦后，就可以利用Federation API资源来统一管理多个集群的Kubernetes API资源，如定义Deployment如何部署到不同集群上，其集群所需的副本数等。

而Kubernetes Federation 的诞生正是希望利用联邦机制来解决一些问题，并达到一些好处，如以下：

- 简化管理多个集群的Kubernetes 组件(如Deployment, Service 等)。
- 在多个集群之间分散工作负载(容器)，以提升应用(服务)的可靠性。
- 跨集群的资源编排，依据编排策略在多个集群进行应用(服务)部署。
- 在不同集群中，能更快速更容易地迁移应用(服务)。
- 跨集群的服务发现，服务可以提供给当地存取，以降低延迟。
- 实践多云(Multi-cloud)或混合云(Hybird Cloud)的部署。

### kubeadm

管理node 的命令行工具

### kubectl

节点内部的命令行工具

### supervisord

*supervisord*是一个轻量级的监控系统，用于保障kubelet和*docker*运行

### fluentd

日志收集器

## 资源对象

### workloads

#### 	deployment

![image-20210608032541111](https://i.loli.net/2021/06/08/kbdzZrjPWlp51Qy.png)

Deployment为Pod和Replica Set提供声明式更新。你只需要在 Deployment 中描述您想要的目标状态是什么，Deployment controller 就会帮您将 Pod 和ReplicaSet 的实际状态改变到您的目标状态。您可以定义一个全新的 Deployment 来创建 ReplicaSet 或者删除已有的 Deployment 并创建一个新的来替换。<font color=orange>也就是说deployment是master用来发布管理你的应用的。</font>

#### 	pod

![image-20210608032634220](https://i.loli.net/2021/06/08/tsaxgE1qy7jNrWZ.png)

- 包含多个共享 IPC、Network 和 UTC namespace 的容器,可直接通过 localhost 通信

- 所有 Pod 内容器都可以访问共享的 Volume,可以访问共享数据

- 无容错性:直接创建的 Pod 一旦被调度后就跟 Node 绑定,即使 Node 挂掉也不会被重新调度(而是被自动删除),因此推荐使用 Deployment、Daemonset 等控制器来容错

- 优雅终止:Pod 删除的时候先给其内的进程发送 SIGTERM,等待一段时间(grace period)后才强制停止依然还在运行的进程

- 特权容器(通过 SecurityContext 配置)具有改变系统配置的权限(在网络插件中大量应用)

<font color=orange>Pod 是一组紧密关联的容器集合,它们共享 IPC、Network 和 UTS namespace,是Kubernetes 调度的基本单位。Pod 的设计理念是支持多个容器在一个 Pod 中共享网络和文件系统,可以通过进程间通信和文件共享这种简单高效的方式组合完成服务。</font>

#### 	ReplicationController

ReplicationController（简称RC）是确保用户定义的Pod副本数保持不变，ReplicationController 的典型应用场景包括确保健康 Pod 的数量、弹性伸缩、滚动升级以及应用多版本发布跟踪等。<font color=red>创建的pod不一定在同一个node中</font>

#### 	replicaSet

ReplicaSet 跟 ReplicationController 没有本质的不同,只是名字不一样,并且 ReplicaSet 支持集合式的 selector(ReplicationController 仅支持等式)。虽然也 ReplicaSet 可以独立使用,但建议使用 Deployment 来自动管理 ReplicaSet,这样就无需担心跟其他机制的不兼容问题(比如 ReplicaSet 不支持 rolling-update 但Deployment 支持),并且还支持版本记录、回滚、暂停升级等高级特性

#### 	StatefulSet

StatefulSet 是为了解决有状态服务的问题(对应 Deployments 和 ReplicaSets 是为无状态服务而设计),其应用场景包括
- 稳定的持久化存储,即 Pod 重新调度后还是能访问到相同的持久化数据,基于PVC 来实现
- 稳定的网络标志,即 Pod 重新调度后其 PodName 和 HostName 不变,基于Headless Service(即没有 Cluster IP 的 Service)来实现
- 有序部署,有序扩展,即 Pod 是有顺序的,在部署或者扩展的时候要依据定义的顺序依次依序进行(即从 0 到 N-1,在下一个 Pod 运行之前所有之前的 Pod 必须都是 Running 和 Ready 状态),基于 init containers 来实现
- 有序收缩,有序删除(即从 N-1 到 0)

#### 	daemonSet

<font color=orange>DaemonSet 保证在每个 Node 上都运行一个容器副本（RS是保证对应pod的数量，pod不一定在同一个node内）,常用来部署一些集群的日志、监控或者其他系统管理应用。</font>典型的应用包括: 

- 日志收集,比如 fluentd,logstash 等
- 系统监控,比如 Prometheus Node Exporter,collectd,New Relic agent,Ganglia gmond 等
- 系统程序,比如 kube-proxy, kube-dns, glusterd, ceph 等

#### 	job

Job 负责批量处理短暂的一次性任务 (short lived one-off tasks),即仅执行一次的任务, 它保证批处理任务的一个或多个 Pod 成功结束。

#### 	Cronjob

CronJob 即定时任务,就类似于 Linux 系统的 crontab,在指定的时间周期运行指定的任务。

#### 	volume

K8s volume 与docker volume不同，k8s volume 有生命周期，详解待日后研究。

### service

#### 	service

![image-20210608032541111](https://i.loli.net/2021/06/08/kbdzZrjPWlp51Qy.png)

Kubernetes Service 定义了这样一种抽象：一个 Pod 的逻辑分组，一种可以访问它们的策略 —— 通常称为微服务。

各种类型的 Service 对源 IP 的处理方法不同: 

- ClusterIP Service:使用 iptables 模式,集群内部的源 IP 会保留(不做 SNAT)。
  如果 client 和 server pod 在同一个 Node 上,那源 IP 就是 client pod 的 IP 地址; 如果在不同的 Node 上,源 IP 则取决于网络插件是如何处理的,比如使用 flannel 时,源 IP 是 node flannel IP 地址。
- NodePort Service:默认情况下,源 IP 会做 SNAT,server pod 看到的源 IP 是Node IP。为了避免这种情况,可以给 service 设置  spec.ExternalTrafficPolicy=Local  (1.6-1.7 版本设置 Annotation   service.beta.kubernetes.io/external-traffic=OnlyLocal ),让 service 只代理本地 endpoint 的请求(如果没有本地 endpoint 则直接丢包),从而保留源IP。
- LoadBalancer Service:默认情况下,源 IP 会做 SNAT,server pod 看到的源 IP 是 Node IP。设置    service.spec.ExternalTrafficPolicy=Local  后可以自动从云平台负载均衡器中删除没有本地 endpoint 的 Node,从而保留源 IP

#### 	ingresses

![image-20210608045218274](https://i.loli.net/2021/06/08/bOyu8QpGDEs4Bxi.png)

通常情况下,service 和 pod 的 IP 仅可在集群内部访问。集群外部的请求需要通过负载均衡转发到 service 在 Node 上暴露的 NodePort 上,然后再由 kube-proxy 通过边缘路由器 (edge router) 将其转发给相关的 Pod 或者丢弃。

### config and storage

#### 	configMaps

ConfigMap 用于保存配置数据的键值对,可以用来保存单个属性,也可以用来保存配置文件

#### 	PersistentVolumeClaim

PersistentVolumes是不属于任何namespace的，但PersistentVolumeClaim是属于某个特定namespace的。

`pvc`是一种`pv`的请求方案，PVC定义我当前需要什么样类型的PV，然后会自动在**当前存在的pv**中选取一个匹配度最高的pv，一个`PVC`只能绑定一个`PV`！估计存储的pv的访问方式。持久卷申领（PersistentVolumeClaim，PVC）表达的是用户对存储的请求。概念上与 Pod 类似，而 PVC 申领会耗用 PV 资源。Pod 可以请求特定数量的资源（CPU 和内存）；同样 PVC 申领也可以请求特定的大小和访问模式

![img](https://i.loli.net/2021/06/07/DEXC6xOiUhLcQwo.jpg)

#### 	StorageClass

集群管理员需要能够提供不同性质的 PersistentVolume，并且这些 PV 卷之间的差别不 仅限于卷大小和访问模式，同时又不能将卷是如何实现的这些细节暴露给用户。 为了满足这类需求，就有了 *存储类（StorageClass）* 资源

#### 	secrets

Secret 解决了密码、token、密钥等敏感数据的配置问题,而不需要把这些敏感数据暴露到镜像或者 Pod Spec 中。

- Opaque:base64 编码格式的 Secret,用来存储密码、密钥等;但数据也通过base64 --decode 解码得到原始数据,所有加密性很弱。
- kubernetes.io/dockerconfigjson :用来存储私有 docker registry 的认证信息。
- kubernetes.io/service-account-token : 用于被 serviceaccount 引用。
    serviceaccout 创建时 Kubernetes 会默认创建对应的 secret。Pod 如果使用了serviceaccount,对应的 secret 会自动挂载到 Pod 的  /run/secrets/kubernetes.io/serviceaccount  目录中。

### Cluster

#### 	node

![image-20210608032733265](https://i.loli.net/2021/06/08/qFMHCrf6EYiwtbd.png)

Node 是 Pod 真正运行的主机,可以是物理机,也可以是虚拟机。为了管理 Pod,每个Node 节点上至少要运行 container runtime(比如    docker  或者    rkt )、   kubelet 和    kube-proxy  服务。

#### 	persistentVolume

PersistentVolumes是不属于任何namespace的，但PersistentVolumeClaim是属于某个特定namespace的。

`PV`可以被理解成`kubernetes`集群中的某个网络存储对应的一块存储，它`与Volume`类似，但是有如下的区别：

1. **PV只能是网络存储**，不属于任何`Node`，但是可以在每个`Node`上访问
2. PV不是被定义在pod上，而是独立在pod之外被定义的。意味着`node`被删除了，`PV`仍然存在，这点与`Volume`不同

#### quota

资源配额(Resource Quotas)是用来限制用户资源用量的一种机制。
它的工作原理为

- 资源配额应用在 Namespace 上,并且每个 Namespace 最多只能有一个  ResourceQuota  对象
- 开启计算资源配额后,创建容器时必须配置计算资源请求或限制(也可以用LimitRange 设置默认值) 
- 用户超额后禁止创建新的资源

#### 	Namespace

Namespace是一种将集群资源划分为多个用途(通过 [resource quota](https://kubernetes.io/docs/concepts/policy/resource-quotas/))的方法。
在未来的Kubernetes版本中，默认情况下，相同Namespace中的对象将具有相同的访问控制策略。
Namespece 是单个节点（node）也就是单机之内的概念，不跨节点

1. <font color=orange>删除一个namespace会自动删除所有属于该namespace的资源。</font>

2. <font color=orange>default和kube-system命名空间不可删除。</font>

3. PersistentVolumes是不属于任何namespace的，但PersistentVolumeClaim是属于某个特定namespace的。

   大多数Kubernetes资源（例如pod、services、replication controllers或其他）都在某些Namespace中，但Namespace资源本身并不在Namespace中。而低级别资源（如[Node](http://docs.kubernetes.org.cn/304.html)和persistentVolumes）不在任何Namespace中。[Events](https://www.kubernetes.org.cn/1031.html)是一个例外：它们可能有也可能没有Namespace，具体取决于[Events](https://www.kubernetes.org.cn/1031.html)的对象

- default 没有指明使用其它名字空间的对象所使用的默认名字空间
- kube-system Kubernetes 系统创建对象所使用的名字空间
- kube-public 这个名字空间是自动创建的，所有用户（包括未经过身份验证的用户）都可以读取它。 这个名字空间主要用于集群使用，以防某些资源在整个集群中应该是可见和可读的。 这个名字空间的公共方面只是一种约定，而不是要求。
- kube-node-lease 此名字空间用于与各个节点相关的租期（Lease）对象； 此对象的设计使得集群规模很大时节点心跳检测性能得到提升。

#### 	Service acount

- 用户账号是针对人而言的。 服务账号是针对运行在 Pod 中的进程而言的。
- 用户账号是全局性的。跨命名空间。服务账号是名字空间作用域的。
- 通常情况下，集群的用户账号可能会从企业数据库进行同步，其创建需要特殊权限， 并且涉及到复杂的业务流程。 服务账号创建有意做得更轻量，允许集群用户为了具体的任务创建服务账号 以遵从权限最小化原则。

#### 	cluster role

#### 	cluster role binding

#### 	role

#### 	role binding

### Custom resource definition

## 心得

#### Pod、service、node、ingresses之间的联系

![image-20210608032541111](https://i.loli.net/2021/06/08/kbdzZrjPWlp51Qy.png)

![image-20210608045218274](https://i.loli.net/2021/06/08/bOyu8QpGDEs4Bxi.png)





