# Kafka的逻辑架构

![img](https://i.loli.net/2021/07/20/XZnJOitvapkq6Qb.png)

![image](https://i.loli.net/2021/07/21/a8wNHUI6eP9htFO.png)

Zookeeper 也支持集群部署。Zookeeper 集群称为 “群组” `Ensemble`。因为 ensemble 也是使用了选举机制，因此每个 ensemble 中有奇数个节点，不建议超过7个。如果我们使用了云原生的 Kafka，就不需要过多关心这个细节

# Kafka中的核心概念

- **Producer:**特指消息的生产者
- **Consumer:**特指消息的消费者  <font color=red>consumer <= partition</font>
- **Consumer Group:**消费者组，可以并行消费Topic中partition的消息。<font color=red>一个`partition`只能被一个`consumer`消费，一个`consumer`可以消费多个`partition`；`partition`里的消息可以广播给不同的`Consumer Group`，但是同一个`Consumer Group`中只能被一个`consumer`消费。</font>

<img src="https://i.loli.net/2021/07/20/7DNUhny6OsxYgM5.png" alt="image-20210720180309451" style="zoom:50%;" />



- **Broker:**缓存代理，Kafka 集群中的一台或多台服务器统称为 broker。
- **Topic:**特指 Kafka 处理的消息源（feeds of messages）的不同分类。
- **Partition:**Topic 物理上的分组，一个 topic 可以分为多个 partition，每个 partition 是一个有序的队列。partition 中的每条消息都会被分配一个有序的 id（offset）。<font color=red>同一分区内可以保证消息有序性，不同分区不能保证消息有序性。</font>
  - kafka基于文件存储.通过分区,可以将日志内容分散到多个server上,来避免文件尺寸达到单机磁盘的上限,每个partiton都会被当前server(kafka实例)保存;
  - 可以将一个topic切分多任意多个partitions,来消息保存/消费的效率.
  - 越多的partitions意味着可以容纳更多的consumer,有效提升并发消费的能力.
- **`Segment：`**partition物理上由多个segment组成。
- **Message:**消息，是通信的基本单位，每个 producer 可以向一个 topic（主题）发布一些消息
  - offset（偏移量，即消息的顺序唯一标示，通过它才能找到唯一的一条消息） 对应类型：long
  - MessageSize 对应类型：int32
  - data    message的具体内容

# Kafka的broker

## 持久化


​    kafka中支持消息持久化的，生产者生产消息后，kafka不会直接把消息传递给消费者，而是先要在broker中进行存储，持久化是保存在kafka的日志文件中。Message在Broker中通Log追加（即新的消息保存在文件的最后面，是有序的）的方式进行持久化存储。并进行分区（patitions)为了减少磁盘写入的次数,broker会将消息暂时buffer起来,当消息的个数(或尺寸)达到一定阀值时,再flush到磁盘,这样减少了磁盘IO调用的次数。

## broker无状态机制

- Broker没有副本机制，一旦broker宕机，该broker的消息将都不可用。

  注：虽然broker没有副本，但是消息本身是有副本的，不会丢失。Broker只要在宕机后再读取消息的日志就行了

- **Broker不保存订阅者的状态，由订阅者自己保存**。

- 无状态导致消息的删除成为难题（可能删除的消息正在被订阅），kafka采用基于时间的SLA(服务水平保证)，消息保存一定时间（通常为7天）后会被删除。

- 消息订阅者可以rewind back到任意位置重新进行消费，当订阅者故障时，可以选择最小的offset(id，即偏移量)进行重新读取消费消息。

  注：1.消费者是如何确定，那条消息应该消费，那条消息已经消费了？
      Zookeeper会帮助记录那条消息已经消费了，那条消息没有消费

  ​    2.消费者是如何快速的找到它没有消费的消息呢？
  ​    这个实现就要靠kafka中 “稀疏索引”

# 生产者

### 发送过程

<img src="https://i.loli.net/2021/07/21/L16GmtUYXHxpTcl.png" alt="image" style="zoom:50%;" />

　　当消息被写入 Kafka broker 之后，broker 会回调到 SDK 中，将消息最终落地的 partition 和 partition 中的 offset 信息返回给 SDK，根据需要返回给 Producer。

### 指定partition

 基于`round-robin`、`hash`或者通过其他的一些算法

### Key 的作用

　　在 producer record 中的 `key` 有两个用途：

1. 作为消息的附加消息
2. 可以用来决定写入到哪一个分区。默认分区器可以使拥有相同 key 的消息写入同一个分区。
3. 如果 key == null，则默认采用轮询方式写入分区
4. 如果 key 非空，则根据哈希结果决定分区

生产者也可以通过自定义分区器来实现业务的具体分区功能，具体参见各语言的 SDK

### 发送方式

#### 同步

　　同步发送方式就是生产者发出的每一个消息，都需要按照上面的结构图的流程处理：消息发出后等待 Kafka broker 的结果响应之后再做进一步的处理。Kafka broker 返回的错误中包含了两种错误：

1. 可重试错误: 当遇到这一类错误时，生产者可以直接重新尝试发送。比如网络错误、集群错误等等。
2. 不可重试错误: 当遇到这一类错误时，生产者只能考虑告警、记录、修改软件逻辑等等。比如消息过大等等。

#### 异步

异步发送方式就是生产者通过 SDK 发送消息之后就直接返回；SDK 在后台处理消息的发送、响应处理，然后通过回调告知生产者以进行进一步的处理（回调这里可以判定保证消息发送成功）。kafka支持异步批量发送消息。批量发送可以很有效的提高发送效率。Kafka producer的异步发送模式允许进行批量发送，先将消息缓存在内存中，然后一次请求批量发送出去。

# 消费者

## Commit

- 自动提交: `enable.auto.commit` 为 `true` 时，API 定时、异步地进行 commit。因此，如果在触发了再均衡的时候还有部分数据未 commit，那么再均衡之后在其他的消费者中就有可能发生重复消费
- 主动提交: `enable.auto.commit` 为 `false` 时，业务方需要主动调用相关 API 进行 commit。
- （主动的）异步提交: 其实就是主动提交的异步版，简单而言就是开一个后台异步 commit 的过程。
- 提交特定的 offset: 这种模式就是显式地 commit 具体 partition 的某个 offset 值。

## 分区再均衡 Partitions Reoke / Rebalance

- 如果 consumer 发生崩溃，或者有新的 consumer 加入 group，就会触发 rebalance。至于是热切换还是冷切换，则由业务方决定。完成 rebalancing 之后，每个 consumer 有可能会被分配到不同的分区。为了能够继续之前的工作，consumer 需要读取每一个分区最后一次提交的 offset，然后从指定的 offset 继续处理。这个操作，一般在 SDK 中就完成了。但是在上述切换过程中，由于分布式系统的分布式、异步特性，我们不可避免的还是可能遇到一些不一致的情况，具体表现为消息的重复处理和漏处理。所以我们在任何时候都不能简单依赖 Kafka 本身提供的消息队列机制，而是在各自的业务系统中也需要进行一定的防御式编程，避免错误处理出现。

　　消费者在调用 `subscribe()` 监听消息时，可以传入一个 `ConsumerRebalanceListener` 实例来监听事件。其中需要关注的事件有：

- `onPartitionsRevoked()`: 这是再平衡开始之前的事件。注意此时消费者应停止消费，并且 commit 已完成但尚未 commit 的 offset 值
- `onPartitionsAssigned()`: 这是再平衡结束，也就是重新分配分区结束之后的时间。大部分情况下消费者也不需要特别处理什么，不过可以在这里进行一些消费过程的重启动作

# 持久化

# 集群

一个独立的 Kafka server 就称为一个 `broker`。一个或多个 broker 可以组成一个 “集群” `broker cluster`。Kafka 虽然是一个分布式的消息队列系统，但是在集群中，Kafka 依然是准中心化的系统架构。也就是说每一个集群中依然是有一台主 broker，称为 `controller`。

每一个 cluster 会自动选举一个 `cluster controller` 出来，controller 需要负责以下操作：

1. 管理 cluster
2. 将 partition 分配给 broker 和监控 broker。


在 cluster 中，一个 partition 会从属于一个 broker，这个 broker 也会称作该 partition 的 `leader`。同时该 partition 也可以分配给多个 broker，进行 **分区复制**——如果其中一个 broker 失效了，那么其余的 broker 可以尽快接管 leader 的位置。如果是使用云原生的 Kafka，我们一般就不需要太担心这个问题。

# 机器配置

从cpu、qps分析机器占用参考：https://segmentfault.com/a/1190000039723251

# 容错

  每个topic的分区都可以分布在Kafka集群的不同服务器上。比如topic A有partition 0,1,2，分别分布在Broker 1,2,3上面。每个服务器都可以处理分布在它上面的分区的写入和读取操作。另外，每个分区也可以配置多个副本用来提高容错性。

  每个partition有一个服务器充当“leader”，零至多个服务器充当“follower”。Leader会处理针对于这个分区的所有读写操作，而follower只是被动的从leader中复制数据。当leader挂掉了，那么原有的follower会自动选举出一个新的leader。每台服务器都会作为一些分区的leader，也会作为其他分区的follower，所以Kafka集群内的负载会比较均衡。

```text	
参考：
		https://www.cnblogs.com/pony1223/p/9807652.html
		https://www.jianshu.com/p/97011dab6c56
		https://segmentfault.com/a/1190000038592433
		https://zhuanlan.zhihu.com/p/88429983
		https://blog.csdn.net/hanjibing1990/article/details/51673540
```

 
