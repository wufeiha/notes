### 共享存储器架构

#### SMP(Symmetric Multi-Processor)

##### 解释

所谓对称多处理器结构，是指服务器中多个CPU对称工作，无主次或从属关系。各CPU共享相同的物理内存，每个 CPU访问内存中的任何地址所需时间是相同的，因此SMP也被称为一致存储器访问结构(UMA：Uniform Memory Access)。

##### 扩展

对SMP服务器进行扩展的方式包括增加内存、使用更快的CPU、增加CPU、扩充I/O(槽口数与总线数)以及添加更多的外部设备(通常是磁盘存储)。

##### 劣势

系统中所有资源(CPU、内存、I/O等)都是共享的，导致了SMP服务器的扩展能力非常有限。对于SMP服务器而言，每一个共享的环节都可能造成SMP服务器扩展时的瓶颈，而最受限制的则是内存。由于每个CPU必须通过相同的内存总线访问相同的内存资源，因此随着CPU数量的增加，内存访问冲突将迅速增加，最终会造成CPU资源的浪费，使 CPU性能的有效性大大降低。实验证明，SMP服务器CPU利用率最好的情况是2至4个CPU。 

#### NUMA(Non-Uniform Memory Access)

![img](https://i.loli.net/2021/04/06/wJGR4dzXBVKDpnQ.gif)

##### 解释

NUMA服务器的基本特征是具有多个CPU模块，<font color=orange>每个CPU模块由多个CPU(如4个)组成，并且具有独立的本地内存、I/O槽口等。</font>由于其节点之间可以通过互联模块(如称为Crossbar Switch)进行连接和信息交互，因此每个CPU可以访问整个系统的内存(这是NUMA系统与MPP系统的重要差别)。显然，访问本地内存的速度将远远高于访问远地内存(系统内其它节点的内存)的速度，这也是非一致存储访问NUMA的由来。

##### 劣势

由于这个特点，为了更好地发挥系统性能，开发应用程序时需要尽量减少不同CPU模块之间的信息交互。但NUMA技术同样有一定缺陷，<font color=orange>由于访问远地内存的延时远远超过本地内存</font>，因此当CPU数量增加时，系统性能无法线性增加。如HP公司发布Superdome服务器时，曾公布了它与HP其它UNIX服务器的相对性能值，结果发现，64路CPU的Superdome (NUMA结构)的相对性能值是20，而8路N4000(共享的SMP结构)的相对性能值是6.3。从这个结果可以看到，8倍数量的CPU换来的只是3倍性能的提升。

#### MPP(Massive Parallel Processing)

![img](https://i.loli.net/2021/04/06/BvH6lJQ9AasrDEC.gif)

##### 解释

由多个SMP服务器通过一定的节点互联网络进行连接，协同工作，完成相同的任务，从用户的角度来看是一个服务器系统。其基本特征是由多个SMP服务器(每个SMP服务器称节点)通过节点互联网络连接而成，<font color=orange>每个节点只访问自己的本地资源(内存、存储等)，是一种完全无共享(Share Nothing)结构</font>，因而扩展能力最好，理论上其扩展无限制，目前的技术可实现512个节点互联，数千个CPU。目前业界对节点互联网络暂无标准，如 NCR的Bynet，IBM的SPSwitch，它们都采用了不同的内部实现机制。但节点互联网仅供MPP服务器内部使用，对用户而言是透明的。

##### vs NUMA

首先是节点互联机制不同，NUMA的节点互联机制是在同一个物理服务器内部实现的，当某个CPU需要进行远地内存访问时，它必须等待，这也是NUMA服务器无法实现CPU增加时性能线性扩展的主要原因。而MPP的节点互联机制是在不同的SMP服务器外部通过I/O 实现的，每个节点只访问本地内存和存储，节点之间的信息交互与节点本身的处理是并行进行的。因此MPP在增加节点时性能基本上可以实现线性扩展。

其次是内存访问机制不同。在NUMA服务器内部，任何一个CPU可以访问整个系统的内存，但远地访问的性能远远低于本地内存访问，因此在开发应用程序时应该尽量避免远地内存访问。在MPP服务器中，每个节点只访问本地内存，不存在远地内存访问的问题。

### 队列锁

#### CLH队列

##### 简单代码实现

```java
public class CLH { 
  //当前节点
  private final ThreadLocal<Node> node = ThreadLocal.withInitial(Node::new);
  //尾节点
  private final AtomicReference<Node> tail = new AtomicReference<>(new Node());

  private static class Node {
    //false代表无人占用锁
    private volatile boolean locked;
  }
  
  public void lock() {
    //得到当前线程的Node节点
    final Node node = this.node.get();
    //修改为true，代表当前线程需要获取锁
    node.locked = true;
    //设置当前线程去注册锁，并返回上一次的加锁节点（前驱节点）
    //仔细体会，这里逻辑上其实形成了链表，有一个排队的过程
    Node pre = this.tail.getAndSet(node);    
    //在前驱节点上自旋
    while (pre.locked) ;
  }
 
  public void unlock() {
    /*
    *当前线程如果释放锁，只要将占用状态改为false即可
    *因为其他的线程会轮询自己，所以volatile布尔变量改变之后
    *会保证下一个线程能立即看到变化，从而得到锁
    */
    final Node node = this.node.get();
    node.locked = false;    
  }
}
```

##### 图解

![clh](https://i.loli.net/2021/04/06/dg8ywH2lNEjKVDe.png)

##### 特点

CLH队列锁的优点是空间复杂度低（如果有n个线程，L个锁，每个线程每次只获取一个锁，那么需要的存储空间是O（L+n），n个线程有n个myNode，L个锁有L个tail），CLH的一种变体被应用在了JAVA并发框架AQS中。CLH在SMP系统结构下是非常有效的。但在NUMA系统结构下，每个线程有自己的内存，如果前趋结点的内存位置比较远，自旋判断前趋结点的locked域，性能将大打折扣，一种解决NUMA系统结构的思路是MCS队列锁。

#### MCS队列

##### 简单代码实现

```java
public class MCS {
  //当前节点
  private final ThreadLocal<Node> node = ThreadLocal.withInitial(Node::new);
  //尾节点
  private final AtomicReference<Node> tail = new AtomicReference<>();

  private static class Node {
    private volatile boolean locked = false;
    private volatile Node next = null;
  }
 
  public void lock() {
    Node node = this.node.get();
    //设置当前节点为占用状态
    node.locked = true;
    //获取前驱节点
    Node pre = tail.getAndSet(node);
    //如果前驱节点不为null，说明有线程已经占用
    if (pre != null) {
      //把前面节点的next指向自己
      pre.next = node;
      //在自己的节点上自旋等待前驱通知
      while (node.locked) ;
    }
  }

  public void unlock() { 
    Node node = this.node.get();
    //判断是不是最后一个线程
    if (node.next == null) {
      //判断是不是自身
      if (tail.compareAndSet(node, null)) {
        return;
      }
      //在判断过程中，又有线程进来
      while (node.next == null) ;
    }
    //本身解锁，通知它的后继节点可以工作了，不用再自旋了
    node.next.locked = false;
    node.next = null;
  }
}
```

##### 图解

![clh](https://i.loli.net/2021/04/06/M3IAGSz8tdnaCUq.png)

##### 特点

MSC与CLH最大的不同并不是链表是显示还是隐式，而是线程自旋的规则不同:CLH是在前趋结点的locked域上自旋等待，而MCS是在自己的结点的locked域上自旋等待。正因为如此，它解决了CLH在NUMA系统架构中获取locked域状态内存过远的问题。

#### CLH 对比 MCS

（1）从代码实现来看，CLH比MCS要简单得多。

（2）从自旋的条件来看，CLH是在前驱节点的属性上自旋，而MCS是在本地属性变量上自旋。

（3）从链表队列来看，CLH的队列是隐式的，CLHNode并不实际持有下一个节点；MCS的队列是物理存在的。

（4）CLH锁释放时只需要改变自己的属性，MCS锁释放则需要改变后继节点的属性。

（5）CLH适合CPU个数不多的计算机硬件架构上，MCS则适合拥有很多CPU的硬件架构上

（6）<font color=orange>CLH和MCS实现的自旋锁都是不可重入的</font>